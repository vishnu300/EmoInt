{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a886aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/statistical/random_forest.py\n",
    "#----------------------------------------------------------\n",
    "# vishnuam300@gmail.com\n",
    "# VISHNU A M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcb64b8",
   "metadata": {},
   "source": [
    "### Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4cd112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e43b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data set function \n",
    "\n",
    "def load_data(filename, label):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    return pd.DataFrame({'text': lines, 'label': label})\n",
    "#Load data\n",
    "sadness = load_data('sadness-ratings-0to1.train.txt', 'sadness')\n",
    "anger = load_data('anger-ratings-0to1.train.txt', 'anger')\n",
    "joy = load_data('joy-ratings-0to1.train.txt', 'joy')\n",
    "fear = load_data('fear-ratings-0to1.train.txt', 'fear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b36c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine data\n",
    "data = pd.concat([sadness, anger, joy, fear], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2438ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8a8b4c",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f9bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Text cleaning function\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text) \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#Apply cleaning\n",
    "data['text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673172e0",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "846f3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "#Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac8521c",
   "metadata": {},
   "source": [
    "### Model Training  and Evaluation\n",
    "\n",
    "###    -- Naive_bayes\n",
    "###    -- RandomForestClassifier\n",
    "###    -- SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e3d9f",
   "metadata": {},
   "source": [
    "### Naivebayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ac985df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9543568464730291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       160\n",
      "           1       0.90      0.99      0.94       230\n",
      "           2       0.98      0.96      0.97       169\n",
      "           3       0.99      0.88      0.93       164\n",
      "\n",
      "    accuracy                           0.95       723\n",
      "   macro avg       0.96      0.95      0.96       723\n",
      "weighted avg       0.96      0.95      0.95       723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#Feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#Evaluate model\n",
    "y_pred = model_nb.predict(X_test_tfidf)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdf30b9",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046ef7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9972337482710927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       160\n",
      "           1       1.00      1.00      1.00       230\n",
      "           2       0.99      1.00      1.00       169\n",
      "           3       1.00      0.99      0.99       164\n",
      "\n",
      "    accuracy                           1.00       723\n",
      "   macro avg       1.00      1.00      1.00       723\n",
      "weighted avg       1.00      1.00      1.00       723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#Train Random Forest model\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#Evaluate model\n",
    "y_pred_Rfc = model_rf.predict(X_test_tfidf)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_Rfc))\n",
    "print(classification_report(y_test, y_pred_Rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca1a436",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a607370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9972337482710927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       160\n",
      "           1       1.00      1.00      1.00       230\n",
      "           2       0.99      1.00      1.00       169\n",
      "           3       1.00      0.99      0.99       164\n",
      "\n",
      "    accuracy                           1.00       723\n",
      "   macro avg       1.00      1.00      1.00       723\n",
      "weighted avg       1.00      1.00      1.00       723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import svm\n",
    "model_Lr = svm.SVC()\n",
    "model_Lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#Evaluate model\n",
    "y_pred_svm = model_Lr.predict(X_test_tfidf)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e627d6ec",
   "metadata": {},
   "source": [
    "## Final Results, Evaluation and comparision of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b41aed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Svm: 0.9972337482710927\n",
      "Accuracy Random Forest: 0.9972337482710927\n",
      "Accuracy Naives: 0.9543568464730291\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Svm:', accuracy_score(y_test, y_pred_svm))\n",
    "print('Accuracy Random Forest:', accuracy_score(y_test, y_pred_Rfc))\n",
    "print('Accuracy Naives:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04259aa",
   "metadata": {},
   "source": [
    "## To check Sample Inputs....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72ce0d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I am feeling very sad and down today. => Predicted Emotion: sadness\n",
      "Text: I am so angry about what happened! => Predicted Emotion: anger\n",
      "Text: I am absolutely overjoyed with the news! => Predicted Emotion: joy\n",
      "Text: I am really scared about the future. => Predicted Emotion: sadness\n"
     ]
    }
   ],
   "source": [
    "sample_texts = [\n",
    "    \"I am feeling very sad and down today.\",\n",
    "    \"I am so angry about what happened!\",\n",
    "    \"I am absolutely overjoyed with the news!\",\n",
    "    \"I am really scared about the future.\"\n",
    "]\n",
    "\n",
    "#Clean the sample inputs\n",
    "cleaned_samples = [clean_text(text) for text in sample_texts]\n",
    "sample_tfidf = vectorizer.transform(cleaned_samples)\n",
    "#Predict the emotion labels\n",
    "sample_predictions = model_rf.predict(sample_tfidf)\n",
    "#Decode the predicted labels\n",
    "decoded_predictions = le.inverse_transform(sample_predictions)\n",
    "\n",
    "#Displays\n",
    "for text, emotion in zip(sample_texts, decoded_predictions):\n",
    "    print(f\"Text: {text} => Predicted Emotion: {emotion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac564c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e5ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9382424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
